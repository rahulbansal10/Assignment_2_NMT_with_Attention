{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"self_attention.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_HQ3hb7ep282","colab_type":"code","outputId":"0c9b7b41-3f1e-43d6-8d02-d594a93ba9f7","executionInfo":{"status":"ok","timestamp":1553961325357,"user_tz":-330,"elapsed":11153,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":394}},"cell_type":"code","source":["from __future__ import absolute_import, division, print_function\n","\n","!pip install tensorflow-gpu==2.0.0-alpha0\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time\n","import nltk\n","nltk.download('punkt')\n","import pickle"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.11.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n","Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.4)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n","Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.6)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.8.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.1)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"metadata":{"id":"T0K2wFjCqA1E","colab_type":"code","outputId":"4e33f9e0-6f4c-4ba9-ac64-d11216873ea0","executionInfo":{"status":"ok","timestamp":1553961325358,"user_tz":-330,"elapsed":9980,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["tf.__version__"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0-alpha0'"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"Fisn5qvW6Wkm","colab_type":"code","outputId":"b0dc2329-67d2-400c-9f11-4844870df21e","executionInfo":{"status":"ok","timestamp":1553961327555,"user_tz":-330,"elapsed":1355,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"irKKr7tMAtLp","colab_type":"code","colab":{}},"cell_type":"code","source":["# Converts the unicode file to ascii\n","def unicode_to_ascii(s):\n","    return ''.join(c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn')\n","\n","\n","def preprocess_sentence(w):\n","    w = unicode_to_ascii(w.lower().strip())\n","    \n","    # creating a space between a word and the punctuation following it\n","    # eg: \"he is a boy.\" => \"he is a boy .\" \n","    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","    \n","    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","    \n","    w = w.rstrip().strip()\n","    \n","    # adding a start and an end token to the sentence\n","    # so that the model know when to start and stop predicting.\n","    w = '<start> ' + w + ' <end>'\n","    return w"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GLrlfVJYD3J-","colab_type":"code","colab":{}},"cell_type":"code","source":["f_en = open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/wmt15-de-en/europarl-v7.de-en.en', 'r')\n","en0 = [preprocess_sentence(e) for e in f_en]\n","f_de = open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/wmt15-de-en/europarl-v7.de-en.de', 'r')\n","de0 = [preprocess_sentence(e) for e in f_de]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dyQG14tG6xMN","colab_type":"code","outputId":"cf663d40-fa3d-4afa-9975-881727093e05","executionInfo":{"status":"ok","timestamp":1553216930025,"user_tz":-330,"elapsed":1754,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"cell_type":"code","source":["print(len(en0))\n","print(de0[1:3])\n","test = \" \".join(de0[1:3])\n","print(test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1920209\n","['<start> ich erklare die am freitag , dem . dezember unterbrochene sitzungsperiode des europaischen parlaments fur wiederaufgenommen , wunsche ihnen nochmals alles gute zum jahreswechsel und hoffe , da sie schone ferien hatten . <end>', '<start> wie sie feststellen konnten , ist der gefurchtete millenium bug nicht eingetreten . doch sind burger einiger unserer mitgliedstaaten opfer von schrecklichen naturkatastrophen geworden . <end>']\n","<start> ich erklare die am freitag , dem . dezember unterbrochene sitzungsperiode des europaischen parlaments fur wiederaufgenommen , wunsche ihnen nochmals alles gute zum jahreswechsel und hoffe , da sie schone ferien hatten . <end> <start> wie sie feststellen konnten , ist der gefurchtete millenium bug nicht eingetreten . doch sind burger einiger unserer mitgliedstaaten opfer von schrecklichen naturkatastrophen geworden . <end>\n"],"name":"stdout"}]},{"metadata":{"id":"frn-TVjPxN1i","colab_type":"code","colab":{}},"cell_type":"code","source":["import nltk\n","from nltk.probability import FreqDist\n","en_corpus = \" \".join(en0)\n","de_corpus = \" \".join(de0)\n","\n","words = nltk.tokenize.word_tokenize(en_corpus)\n","fdist_en = FreqDist(words)\n","en_top = fdist_en.most_common(30000)\n","\n","words = nltk.tokenize.word_tokenize(de_corpus)\n","fdist_de = FreqDist(words)\n","de_top = fdist_de.most_common(30000)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hB4HO9QL7nOJ","colab_type":"code","outputId":"0962e53c-bc1d-4bef-ff76-c28051be2ddd","executionInfo":{"status":"ok","timestamp":1553217882121,"user_tz":-330,"elapsed":1362,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"cell_type":"code","source":["en_words = [e[0] for e in (en_top)]\n","de_words = [s[0] for s in (de_top)]\n","print(en_words[1:15])\n","print(de_words[1:15])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['>', 'the', ',', 'end', 'start', '.', 'of', 'to', 'and', 'in', 'that', 'a', 'is', 'for']\n","['>', ',', '.', 'die', 'end', 'start', 'der', 'und', 'in', 'zu', 'den', 'wir', 'ich', 'fur']\n"],"name":"stdout"}]},{"metadata":{"id":"7Kw4Dw6QDkuC","colab_type":"code","colab":{}},"cell_type":"code","source":["en = list()\n","de = list()\n","for i in range(len(en0)):\n","  en_ = en0[i].split(' ')\n","  for j in range(len(en_)):\n","    if en_[j] in en_words or en_[j]=='<start>' or en_[j]=='<end>':\n","      temp = 2\n","    else:\n","      en_[j] = 'UNK'\n","  en_ = ' '.join(en_)\n","  en.append(en_)\n","  \n","  \n","  de_ = de0[i].split(' ')\n","  for j in range(len(de_)):\n","    if de_[j] in de_words or de_[j]=='<start>' or de_[j]=='<end>':\n","      temp = 2\n","    else:\n","       de_[j] = 'UNK'\n","  de_ = ' '.join(de_)\n","  de.append(de_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XQaQY6KT61XA","colab_type":"code","outputId":"41453644-c12c-4a21-b44a-ba297de1ba16","executionInfo":{"status":"ok","timestamp":1553230530825,"user_tz":-330,"elapsed":2886,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"cell_type":"code","source":["print(en[12])\n","print(de[100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<start> if the house agrees , i shall do as mr evans has suggested . <end>\n","<start> jetzt mochte ich zur sache selbst etwas sagen . <end>\n"],"name":"stdout"}]},{"metadata":{"id":"yaXbkmwcTXrF","colab_type":"code","colab":{}},"cell_type":"code","source":["pickle.dump(en, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_europarl-v7.de-en.en', 'wb'))\n","pickle.dump(de, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_europarl-v7.de-en.de', 'wb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SNncl4inwxKs","colab_type":"code","colab":{}},"cell_type":"code","source":["en = pickle.load(open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_europarl-v7.de-en.en', 'rb'))\n","de = pickle.load(open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_europarl-v7.de-en.de', 'rb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hGNREZTxxLyL","colab_type":"code","outputId":"2839981d-f3e1-42a4-b7fc-5a478605533e","executionInfo":{"status":"ok","timestamp":1553961342680,"user_tz":-330,"elapsed":1651,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["print(en[1])\n","print(de[1])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["<start> i declare resumed the session of the european parliament adjourned on friday december , and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period . <end>\n","<start> ich erklare die am freitag , dem . dezember unterbrochene sitzungsperiode des europaischen parlaments fur wiederaufgenommen , wunsche ihnen nochmals alles gute zum jahreswechsel und hoffe , da sie schone ferien hatten . <end>\n"],"name":"stdout"}]},{"metadata":{"id":"0peFkfmwElcJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def max_length(tensor):\n","    return max(len(t) for t in tensor)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3101JiJhGdCc","colab_type":"code","colab":{}},"cell_type":"code","source":["def tokenize(lang):\n","  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","      filters='')\n","  lang_tokenizer.fit_on_texts(lang)\n","  \n","  tensor = lang_tokenizer.texts_to_sequences(lang)\n","  \n","  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, maxlen =20,padding='post')\n","  \n","  return tensor, lang_tokenizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MD0mg0r1Gg81","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_dataset():\n","\n","    input_tensor, inp_lang_tokenizer = tokenize(en)\n","    target_tensor, targ_lang_tokenizer = tokenize(de)\n","\n","    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nmEcEuohGlZR","colab_type":"code","colab":{}},"cell_type":"code","source":["input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()\n","\n","# Calculate max_length of the target tensors\n","max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"liEYcThGGp__","colab_type":"code","outputId":"a642ff4a-c96e-4c72-bc61-f911e31f0312","executionInfo":{"status":"ok","timestamp":1553961597635,"user_tz":-330,"elapsed":1271,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n","# Show length\n","len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1728188, 1728188, 192021, 192021)"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"wSnWrzPQG3mE","colab_type":"code","colab":{}},"cell_type":"code","source":["def inp_convert(lang, tensor):\n","  s = ''\n","  for t in tensor:\n","    if (t!=3 and t!=4 and t!=0):\n","      s = s + ' ' + lang.index_word[t]\n","    else:\n","      temp = 2\n","      #print (\"%d ----> %s\" % (t, lang.index_word[t]))\n","  return s[1:].split(' ')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q5n7We1xuduM","colab_type":"code","colab":{}},"cell_type":"code","source":["def tar_convert(lang, tensor):\n","  s = ''\n","  for t in tensor:\n","    if (t!=4 and t!=0):\n","      s = s + ' ' + lang.index_word[t]\n","    else:\n","      temp = 2\n","      #print (\"%d ----> %s\" % (t, lang.index_word[t]))\n","  return s[1:].split(' ')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-YLeH_lwHz4n","colab_type":"code","outputId":"57ae6293-2d46-46b9-8bc5-7bbe7f94143a","executionInfo":{"status":"ok","timestamp":1553961600166,"user_tz":-330,"elapsed":1206,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["#inp_lang.index_word[0]\n","print (\"Input Language; index to word mapping\")\n","s1 = (inp_convert(inp_lang, input_tensor_train[0]))\n","print(s1)\n","print (\"Target Language; index to word mapping\")\n","s2 = (tar_convert(targ_lang, target_tensor_train[0]))\n","print(s2)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Input Language; index to word mapping\n","['thank', 'you', ',', 'commissioner', '.']\n","Target Language; index to word mapping\n","['vielen', 'dank', ',', 'frau', 'kommissarin', '.', '<end>']\n"],"name":"stdout"}]},{"metadata":{"id":"JvonfPCBJj8r","colab_type":"code","colab":{}},"cell_type":"code","source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 128\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 128\n","units = 512\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J2ztPjI_J56k","colab_type":"code","outputId":"75cc4411-46d2-4864-d55d-b6aa124bd3c0","executionInfo":{"status":"ok","timestamp":1553961615115,"user_tz":-330,"elapsed":13634,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["example_input_batch, example_target_batch = next(iter(dataset))\n","print(example_input_batch.shape, example_target_batch.shape)\n","print(vocab_inp_size)\n","print(vocab_tar_size)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["(128, 20) (128, 20)\n","30002\n","30002\n"],"name":"stdout"}]},{"metadata":{"id":"_OZDK-q2J8pG","colab_type":"code","colab":{}},"cell_type":"code","source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.enc_units, \n","                                   return_sequences=True, \n","                                   return_state=True, \n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    #print(x.shape)\n","    x = self.embedding(x)\n","    #print(x.shape)\n","    output, state = self.gru(x, initial_state = hidden)        \n","    return output, state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1iQ_g9tJOQlp","colab_type":"code","outputId":"3191b6f4-06e1-4f91-bbf7-50be92a80a68","executionInfo":{"status":"ok","timestamp":1553961621415,"user_tz":-330,"elapsed":2198,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (128, 20, 512)\n","Encoder Hidden state shape: (batch size, units) (128, 512)\n"],"name":"stdout"}]},{"metadata":{"id":"mjGUt-a4OT-i","colab_type":"code","colab":{}},"cell_type":"code","source":["class SelfAttention(tf.keras.Model):\n","  def __init__(self, units):\n","    super(SelfAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","  \n","  def call(self, query, values):\n","    # hidden shape == (batch_size, hidden size)\n","    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n","    # we are doing this to perform addition to calculate the score\n","    hidden_with_time_axis = tf.expand_dims(query, 1)\n","    #print('shape of query is {}'.format(query.shape))\n","    #print('shape of hidden_with_time_axis is {}'.format(hidden_with_time_axis.shape))\n","    #print('shape of values {}'.format(values.shape))\n","    #print('shape of self.W1(values) is {}'.format(self.W1(values).shape))\n","    #print('shape of self.W2(hidden_with_time_axis) is {}'.format(self.W2(hidden_with_time_axis).shape))\n","\n","    # score shape == (batch_size, max_length, hidden_size)\n","    score = self.V(tf.nn.tanh(\n","        self.W1(values)))\n","    \n","    #print('shape of score is {}'.format(score.shape))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","    #print('shape of attention_weights {}'.format(attention_weights.shape))\n","    \n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","    #print(context_vector.shape)\n","    \n","    return context_vector, attention_weights"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HeVRfOg7OlUl","colab_type":"code","outputId":"9436071d-5683-4172-ab26-67657bc67f10","executionInfo":{"status":"ok","timestamp":1553961625918,"user_tz":-330,"elapsed":1829,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["attention_layer = SelfAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Attention result shape: (batch size, units) (128, 512)\n","Attention weights shape: (batch_size, sequence_length, 1) (128, 20, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"V8WxPF6jOpUo","colab_type":"code","colab":{}},"cell_type":"code","source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.dec_units, \n","                                   return_sequences=True, \n","                                   return_state=True, \n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    self.attention = SelfAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","    #print(context_vector.shape)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    #print(x.shape)\n","    x = self.embedding(x)\n","    #print(x.shape)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","    #print(x.shape)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","    #print(output.shape)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","    #print(output.shape)\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u0c1vMqlOxsC","colab_type":"code","outputId":"a257bc9b-8964-4a07-9d7c-0e464c9d0410","executionInfo":{"status":"ok","timestamp":1553961709161,"user_tz":-330,"elapsed":2343,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), \n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Decoder output shape: (batch_size, vocab size) (128, 30002)\n"],"name":"stdout"}]},{"metadata":{"id":"d4ELsZkqSpbl","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  \n","  return tf.reduce_mean(loss_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tzSb24up0aZs","colab_type":"code","colab":{}},"cell_type":"code","source":["checkpoint_dir = '/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/self_attention/training_checkpoints_2'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aKnrVbnX0c6A","colab_type":"code","colab":{}},"cell_type":"code","source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","        \n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)       \n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","      # passing enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # using teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","  \n","  return batch_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NcF1uNst0gVo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2152},"outputId":"d518dd48-ea42-48ff-f5af-3c97c653eed7","executionInfo":{"status":"error","timestamp":1553970845173,"user_tz":-330,"elapsed":2934748,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}}},"cell_type":"code","source":["EPOCHS = 4\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                     batch,\n","                                                     batch_loss.numpy()))\n","  # saving (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 1 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","    #pickle.dump(optimizer, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_optimizer', 'wb'))\n","    #pickle.dump(encoder, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_encoder', 'wb'))\n","    #pickle.dump(decoder, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_decoder', 'wb'))\n","    \n","\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 2.2147\n","Epoch 1 Batch 100 Loss 2.1615\n","Epoch 1 Batch 200 Loss 2.2526\n","Epoch 1 Batch 300 Loss 2.1744\n","Epoch 1 Batch 400 Loss 2.1198\n","Epoch 1 Batch 500 Loss 2.1519\n","Epoch 1 Batch 600 Loss 2.4807\n","Epoch 1 Batch 700 Loss 2.3882\n","Epoch 1 Batch 800 Loss 2.4874\n","Epoch 1 Batch 900 Loss 2.4266\n","Epoch 1 Batch 1000 Loss 2.4362\n","Epoch 1 Batch 1100 Loss 2.4694\n","Epoch 1 Batch 1200 Loss 2.5865\n","Epoch 1 Batch 1300 Loss 2.5484\n","Epoch 1 Batch 1400 Loss 2.1836\n","Epoch 1 Batch 1500 Loss 2.4317\n","Epoch 1 Batch 1600 Loss 2.4934\n","Epoch 1 Batch 1700 Loss 2.3282\n","Epoch 1 Batch 1800 Loss 2.4265\n","Epoch 1 Batch 1900 Loss 2.3805\n","Epoch 1 Batch 2000 Loss 2.4224\n","Epoch 1 Batch 2100 Loss 2.4073\n","Epoch 1 Batch 2200 Loss 2.4885\n","Epoch 1 Batch 2300 Loss 2.4250\n","Epoch 1 Batch 2400 Loss 2.4107\n","Epoch 1 Batch 2500 Loss 2.2168\n","Epoch 1 Batch 2600 Loss 2.2671\n","Epoch 1 Batch 2700 Loss 2.3467\n","Epoch 1 Batch 2800 Loss 2.3105\n","Epoch 1 Batch 2900 Loss 2.3920\n","Epoch 1 Batch 3000 Loss 2.5334\n","Epoch 1 Batch 3100 Loss 2.3760\n","Epoch 1 Batch 3200 Loss 2.4963\n","Epoch 1 Batch 3300 Loss 2.3607\n","Epoch 1 Batch 3400 Loss 2.2413\n","Epoch 1 Batch 3500 Loss 2.2541\n","Epoch 1 Batch 3600 Loss 2.6009\n","Epoch 1 Batch 3700 Loss 2.4547\n","Epoch 1 Batch 3800 Loss 2.4952\n","Epoch 1 Batch 3900 Loss 2.3326\n","Epoch 1 Batch 4000 Loss 2.3116\n","Epoch 1 Batch 4100 Loss 2.4729\n","Epoch 1 Batch 4200 Loss 2.2550\n","Epoch 1 Batch 4300 Loss 2.5906\n","Epoch 1 Batch 4400 Loss 2.2337\n","Epoch 1 Batch 4500 Loss 2.3084\n","Epoch 1 Batch 4600 Loss 2.2582\n","Epoch 1 Batch 4700 Loss 2.3919\n","Epoch 1 Batch 4800 Loss 2.3325\n","Epoch 1 Batch 4900 Loss 2.1899\n","Epoch 1 Batch 5000 Loss 2.4355\n","Epoch 1 Batch 5100 Loss 2.3937\n","Epoch 1 Batch 5200 Loss 2.3085\n","Epoch 1 Batch 5300 Loss 2.3641\n","Epoch 1 Batch 5400 Loss 2.5837\n","Epoch 1 Batch 5500 Loss 2.3532\n","Epoch 1 Batch 5600 Loss 2.3449\n","Epoch 1 Batch 5700 Loss 2.4277\n","Epoch 1 Batch 5800 Loss 2.3617\n","Epoch 1 Batch 5900 Loss 2.4686\n","Epoch 1 Batch 6000 Loss 2.3781\n","Epoch 1 Batch 6100 Loss 2.4131\n","Epoch 1 Batch 6200 Loss 2.2100\n","Epoch 1 Batch 6300 Loss 2.3366\n","Epoch 1 Batch 6400 Loss 2.3809\n","Epoch 1 Batch 6500 Loss 2.2668\n","Epoch 1 Batch 6600 Loss 2.6301\n","Epoch 1 Batch 6700 Loss 2.2260\n","Epoch 1 Batch 6800 Loss 2.3503\n","Epoch 1 Batch 6900 Loss 2.2848\n","Epoch 1 Batch 7000 Loss 2.5728\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-74cf53934310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    412\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \"\"\"\n\u001b[1;32m    573\u001b[0m     return self._call_flat(\n\u001b[0;32m--> 574\u001b[0;31m         (t for t in nest.flatten((args, kwargs))\n\u001b[0m\u001b[1;32m    575\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m    576\u001b[0m                            resource_variable_ops.ResourceVariable))))\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"1vp4t2Nt0liP","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluate(sentence):\n","    attention_plot = np.zeros((max_length_targ, max_length_inp))\n","    \n","    sentence = preprocess_sentence(sentence)\n","\n","    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], \n","                                                           maxlen=max_length_inp, \n","                                                           padding='post')\n","    inputs = tf.convert_to_tensor(inputs)\n","    \n","    result = ''\n","\n","    hidden = [tf.zeros((1, units))]\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    dec_hidden = enc_hidden\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","    \n","    for t in range(max_length_targ):\n","        predictions, dec_hidden, attention_weights = decoder(dec_input, \n","                                                             dec_hidden, \n","                                                             enc_out)\n","        \n","        # storing the attention weights to plot later on\n","        attention_weights = tf.reshape(attention_weights, (-1, ))\n","        attention_plot[t] = attention_weights.numpy()\n","\n","        predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += targ_lang.index_word[predicted_id] + ' '\n","\n","        if targ_lang.index_word[predicted_id] == '<end>':\n","            return result, sentence, attention_plot\n","        \n","        # the predicted ID is fed back into the model\n","        dec_input = tf.expand_dims([predicted_id], 0)\n","\n","    return result, sentence, attention_plot"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dhQAhDWb5WLu","colab_type":"code","colab":{}},"cell_type":"code","source":["# function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","    fig = plt.figure(figsize=(4,4))\n","    ax = fig.add_subplot(1, 1, 1)\n","    ax.matshow(attention, cmap='viridis')\n","    \n","    fontdict = {'fontsize': 10}\n","    \n","    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n","    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n","    #plt.savefig('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/self_attention/fig3_self_attention')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IP8ho2tL5W-U","colab_type":"code","colab":{}},"cell_type":"code","source":["def translate(sentence):\n","    result, sentence, attention_plot = evaluate(sentence)\n","        \n","    print('Input: %s' % (sentence).encode('utf-8'))\n","    print('Predicted translation: {}'.format(result))\n","    \n","    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n","    return result"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LEoeGP8iGikf","colab_type":"code","colab":{}},"cell_type":"code","source":["def translate_tmp(sentence):\n","    result, sentence, attention_plot = evaluate(sentence)\n","        \n","    #print('Input: %s' % (sentence).encode('utf-8'))\n","    #print('Predicted translation: {}'.format(result))\n","    \n","    #attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","    #plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n","    return result"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ryneNZKZ5Z9X","colab_type":"code","outputId":"aefc61a4-a158-4574-d550-a94277f3a8f9","executionInfo":{"status":"ok","timestamp":1553967310708,"user_tz":-330,"elapsed":2365,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# restoring the latest checkpoint in checkpoint_dir\n","#checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fecdcdb0b38>"]},"metadata":{"tags":[]},"execution_count":47}]},{"metadata":{"id":"5QxQCSAIFGpp","colab_type":"code","outputId":"98fbd605-9d4e-4cf2-ea47-2d433211f649","executionInfo":{"status":"ok","timestamp":1553971955649,"user_tz":-330,"elapsed":1841,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":259}},"cell_type":"code","source":["#s = translate(' '.join(inp_convert(inp_lang, input_tensor_train[25]))).split(' ')\n","s = translate('the problems with fishmeal lie elsewhere .')\n","print(s)"],"execution_count":101,"outputs":[{"output_type":"stream","text":["Input: b'<start> the problems with fishmeal lie elsewhere . <end>'\n","Predicted translation: die fischmehl . <end> \n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAR8AAAC/CAYAAADHPNgXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["die fischmehl . <end> \n"],"name":"stdout"}]},{"metadata":{"id":"sNFHQujn5dVh","colab_type":"code","colab":{}},"cell_type":"code","source":["ref = list()\n","for i in range(1000):\n","  ref_tmp = list()\n","  ref_tmp.append(tar_convert(targ_lang, target_tensor_val[i]))\n","  ref.append(ref_tmp)\n","  \n","cand = list()\n","for i in range(1000):\n","  s = translate_tmp(' '.join(inp_convert(inp_lang, input_tensor_val[i]))).split(' ')\n","  cand.append(s)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2qSEo5YZdaWI","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","pickle.dump(cand, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/bahadanau_attention/pickle_candidate_translation', 'wb'))\n","pickle.dump(ref, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/bahadanau_attention/pickle_reference_translation', 'wb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GpdXSa_e5gTk","colab_type":"code","outputId":"e473f723-7cab-4a5d-c4e9-564e185a97bc","executionInfo":{"status":"ok","timestamp":1553971772403,"user_tz":-330,"elapsed":1773,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":["print(ref[0:5])\n","print(cand[0:5])\n","print(len(ref))\n","print(len(cand))"],"execution_count":96,"outputs":[{"output_type":"stream","text":["[[['ich', 'teile', 'ihnen', 'mit', ',', 'da', 'ich', 'gema', 'artikel', 'absatz', 'der', 'geschaftsordnung', 'einen', 'entschlie', 'ungsantrag', 'erhalten', 'habe', '.', '<end>']], [['es', 'gibt', 'ganz', 'konkrete', 'falle', 'von', 'kleinkinder', 'unk', '.', '<end>']], [['vielen', 'dank', ',', 'herr', 'kommissar', '!', '<end>']], [['die', 'arbeitslosigkeit', 'in', 'der', 'eu', 'wird', 'ein', 'immer', 'unk', 'problem', '.', '<end>']], [['konnte', 'die', 'kommission', 'bitte', 'alsbald', 'dieser', 'sache', 'nachgehen', '?', '<end>']]]\n","[['einen', 'entschlie', 'ungsantrag', 'eingereicht', 'wurde', '.', '<end>', ''], ['es', 'gab', 'es', 'gab', 'es', 'gab', 'es', 'gab', 'es', 'gab', 'es', 'gab', 'es', 'gab', 'es', 'gab', 'es', 'gab', 'es', 'gab', ''], ['vielen', 'dank', ',', 'herr', 'kommissar', '.', '<end>', ''], ['die', 'arbeitslosigkeit', 'wird', 'immer', 'ein', 'wachsendes', 'problem', '.', '<end>', ''], ['kann', 'die', 'kommission', 'die', 'kommission', 'die', 'kommission', 'die', 'kommission', 'die', 'kommission', 'die', 'kommission', 'die', 'kommission', 'die', 'kommission', 'die', 'kommission', 'die', '']]\n","1000\n","1000\n"],"name":"stdout"}]},{"metadata":{"id":"wanR8twMDV25","colab_type":"code","outputId":"aaf537e9-6468-4ed2-eaaa-6ec7df40f82e","executionInfo":{"status":"ok","timestamp":1553971775163,"user_tz":-330,"elapsed":1891,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# two references for one document\n","from nltk.translate.bleu_score import corpus_bleu\n","#references = [[['this', 'is', 'a', 'test'], ['this', 'is' 'test']]]\n","#candidates = [['this', 'is', 'a', 'test']]\n","score = corpus_bleu(ref, cand)\n","print(score)"],"execution_count":97,"outputs":[{"output_type":"stream","text":["0.06317464224006847\n"],"name":"stdout"}]},{"metadata":{"id":"XbjAUtDSd719","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b6b385b5-5e14-4e3f-e9a6-4bd54f7c6a80","executionInfo":{"status":"ok","timestamp":1553954110285,"user_tz":-330,"elapsed":1527,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}}},"cell_type":"code","source":["s = ['nn','dgc']\n","s = ['dhdh'] + s\n","print(s)"],"execution_count":57,"outputs":[{"output_type":"stream","text":["['dhdh', 'nn', 'dgc']\n"],"name":"stdout"}]},{"metadata":{"id":"z1OoE7Go4BIn","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}