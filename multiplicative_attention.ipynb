{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multiplicative_attention.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_HQ3hb7ep282","colab_type":"code","outputId":"318dc5ff-6512-43bf-db5a-10cf12f24c2f","executionInfo":{"status":"ok","timestamp":1553944289061,"user_tz":-330,"elapsed":12750,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":394}},"cell_type":"code","source":["from __future__ import absolute_import, division, print_function\n","\n","!pip install tensorflow-gpu==2.0.0-alpha0\n","import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time\n","import nltk\n","nltk.download('punkt')\n","import pickle"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n","Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n","Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.4)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n","Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.6)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.11.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (40.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"metadata":{"id":"T0K2wFjCqA1E","colab_type":"code","outputId":"e0f45c04-aafb-4f95-fe51-8789728341b2","executionInfo":{"status":"ok","timestamp":1553944292038,"user_tz":-330,"elapsed":1190,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["tf.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0-alpha0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"Fisn5qvW6Wkm","colab_type":"code","outputId":"d9fafb88-fe1c-4511-efa2-49dde2e30961","executionInfo":{"status":"ok","timestamp":1553944294119,"user_tz":-330,"elapsed":1480,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"irKKr7tMAtLp","colab_type":"code","colab":{}},"cell_type":"code","source":["# Converts the unicode file to ascii\n","def unicode_to_ascii(s):\n","    return ''.join(c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn')\n","\n","\n","def preprocess_sentence(w):\n","    w = unicode_to_ascii(w.lower().strip())\n","    \n","    # creating a space between a word and the punctuation following it\n","    # eg: \"he is a boy.\" => \"he is a boy .\" \n","    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n","    w = re.sub(r'[\" \"]+', \" \", w)\n","    \n","    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n","    \n","    w = w.rstrip().strip()\n","    \n","    # adding a start and an end token to the sentence\n","    # so that the model know when to start and stop predicting.\n","    w = '<start> ' + w + ' <end>'\n","    return w"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GLrlfVJYD3J-","colab_type":"code","colab":{}},"cell_type":"code","source":["f_en = open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/wmt15-de-en/europarl-v7.de-en.en', 'r')\n","en0 = [preprocess_sentence(e) for e in f_en]\n","f_de = open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/wmt15-de-en/europarl-v7.de-en.de', 'r')\n","de0 = [preprocess_sentence(e) for e in f_de]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dyQG14tG6xMN","colab_type":"code","outputId":"cf663d40-fa3d-4afa-9975-881727093e05","executionInfo":{"status":"ok","timestamp":1553216930025,"user_tz":-330,"elapsed":1754,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"cell_type":"code","source":["print(len(en0))\n","print(de0[1:3])\n","test = \" \".join(de0[1:3])\n","print(test)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1920209\n","['<start> ich erklare die am freitag , dem . dezember unterbrochene sitzungsperiode des europaischen parlaments fur wiederaufgenommen , wunsche ihnen nochmals alles gute zum jahreswechsel und hoffe , da sie schone ferien hatten . <end>', '<start> wie sie feststellen konnten , ist der gefurchtete millenium bug nicht eingetreten . doch sind burger einiger unserer mitgliedstaaten opfer von schrecklichen naturkatastrophen geworden . <end>']\n","<start> ich erklare die am freitag , dem . dezember unterbrochene sitzungsperiode des europaischen parlaments fur wiederaufgenommen , wunsche ihnen nochmals alles gute zum jahreswechsel und hoffe , da sie schone ferien hatten . <end> <start> wie sie feststellen konnten , ist der gefurchtete millenium bug nicht eingetreten . doch sind burger einiger unserer mitgliedstaaten opfer von schrecklichen naturkatastrophen geworden . <end>\n"],"name":"stdout"}]},{"metadata":{"id":"frn-TVjPxN1i","colab_type":"code","colab":{}},"cell_type":"code","source":["import nltk\n","from nltk.probability import FreqDist\n","en_corpus = \" \".join(en0)\n","de_corpus = \" \".join(de0)\n","\n","words = nltk.tokenize.word_tokenize(en_corpus)\n","fdist_en = FreqDist(words)\n","en_top = fdist_en.most_common(30000)\n","\n","words = nltk.tokenize.word_tokenize(de_corpus)\n","fdist_de = FreqDist(words)\n","de_top = fdist_de.most_common(30000)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hB4HO9QL7nOJ","colab_type":"code","outputId":"0962e53c-bc1d-4bef-ff76-c28051be2ddd","executionInfo":{"status":"ok","timestamp":1553217882121,"user_tz":-330,"elapsed":1362,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"cell_type":"code","source":["en_words = [e[0] for e in (en_top)]\n","de_words = [s[0] for s in (de_top)]\n","print(en_words[1:15])\n","print(de_words[1:15])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['>', 'the', ',', 'end', 'start', '.', 'of', 'to', 'and', 'in', 'that', 'a', 'is', 'for']\n","['>', ',', '.', 'die', 'end', 'start', 'der', 'und', 'in', 'zu', 'den', 'wir', 'ich', 'fur']\n"],"name":"stdout"}]},{"metadata":{"id":"7Kw4Dw6QDkuC","colab_type":"code","colab":{}},"cell_type":"code","source":["en = list()\n","de = list()\n","for i in range(len(en0)):\n","  en_ = en0[i].split(' ')\n","  for j in range(len(en_)):\n","    if en_[j] in en_words or en_[j]=='<start>' or en_[j]=='<end>':\n","      temp = 2\n","    else:\n","      en_[j] = 'UNK'\n","  en_ = ' '.join(en_)\n","  en.append(en_)\n","  \n","  \n","  de_ = de0[i].split(' ')\n","  for j in range(len(de_)):\n","    if de_[j] in de_words or de_[j]=='<start>' or de_[j]=='<end>':\n","      temp = 2\n","    else:\n","       de_[j] = 'UNK'\n","  de_ = ' '.join(de_)\n","  de.append(de_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XQaQY6KT61XA","colab_type":"code","outputId":"41453644-c12c-4a21-b44a-ba297de1ba16","executionInfo":{"status":"ok","timestamp":1553230530825,"user_tz":-330,"elapsed":2886,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"cell_type":"code","source":["print(en[12])\n","print(de[100])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<start> if the house agrees , i shall do as mr evans has suggested . <end>\n","<start> jetzt mochte ich zur sache selbst etwas sagen . <end>\n"],"name":"stdout"}]},{"metadata":{"id":"yaXbkmwcTXrF","colab_type":"code","colab":{}},"cell_type":"code","source":["pickle.dump(en, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_europarl-v7.de-en.en', 'wb'))\n","pickle.dump(de, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_europarl-v7.de-en.de', 'wb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SNncl4inwxKs","colab_type":"code","colab":{}},"cell_type":"code","source":["en = pickle.load(open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_europarl-v7.de-en.en', 'rb'))\n","de = pickle.load(open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_europarl-v7.de-en.de', 'rb'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hGNREZTxxLyL","colab_type":"code","outputId":"9af10104-b883-4b4c-aba2-85c1966de6e7","executionInfo":{"status":"ok","timestamp":1553944324915,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["print(en[1])\n","print(de[1])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["<start> i declare resumed the session of the european parliament adjourned on friday december , and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period . <end>\n","<start> ich erklare die am freitag , dem . dezember unterbrochene sitzungsperiode des europaischen parlaments fur wiederaufgenommen , wunsche ihnen nochmals alles gute zum jahreswechsel und hoffe , da sie schone ferien hatten . <end>\n"],"name":"stdout"}]},{"metadata":{"id":"0peFkfmwElcJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def max_length(tensor):\n","    return max(len(t) for t in tensor)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3101JiJhGdCc","colab_type":"code","colab":{}},"cell_type":"code","source":["def tokenize(lang):\n","  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","      filters='')\n","  lang_tokenizer.fit_on_texts(lang)\n","  \n","  tensor = lang_tokenizer.texts_to_sequences(lang)\n","  \n","  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, maxlen =20,padding='post')\n","  \n","  return tensor, lang_tokenizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MD0mg0r1Gg81","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_dataset():\n","\n","    input_tensor, inp_lang_tokenizer = tokenize(en)\n","    target_tensor, targ_lang_tokenizer = tokenize(de)\n","\n","    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nmEcEuohGlZR","colab_type":"code","colab":{}},"cell_type":"code","source":["input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()\n","\n","# Calculate max_length of the target tensors\n","max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QqPXrgpIkXje","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8e631ad1-cb62-4367-888c-ae8e04b8512c","executionInfo":{"status":"ok","timestamp":1553948852467,"user_tz":-330,"elapsed":3249,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}}},"cell_type":"code","source":["max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n","print(max_length_targ)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["20\n"],"name":"stdout"}]},{"metadata":{"id":"liEYcThGGp__","colab_type":"code","outputId":"75a7468f-8e30-4b16-9e2a-7331cac5179f","executionInfo":{"status":"ok","timestamp":1553944747545,"user_tz":-330,"elapsed":298151,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1)\n","# Show length\n","len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1728188, 1728188, 192021, 192021)"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"wSnWrzPQG3mE","colab_type":"code","colab":{}},"cell_type":"code","source":["def inp_convert(lang, tensor):\n","  s = ''\n","  for t in tensor:\n","    if (t!=3 and t!=4 and t!=0):\n","      s = s + ' ' + lang.index_word[t]\n","    else:\n","      temp = 2\n","      #print (\"%d ----> %s\" % (t, lang.index_word[t]))\n","  return s[1:].split(' ')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q5n7We1xuduM","colab_type":"code","colab":{}},"cell_type":"code","source":["def tar_convert(lang, tensor):\n","  s = ''\n","  for t in tensor:\n","    if (t!=4 and t!=0):\n","      s = s + ' ' + lang.index_word[t]\n","    else:\n","      temp = 2\n","      #print (\"%d ----> %s\" % (t, lang.index_word[t]))\n","  return s[1:].split(' ')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-YLeH_lwHz4n","colab_type":"code","outputId":"d692e616-cc44-48ca-881e-85b127bd754c","executionInfo":{"status":"ok","timestamp":1553944747550,"user_tz":-330,"elapsed":296771,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"cell_type":"code","source":["#inp_lang.index_word[0]\n","print (\"Input Language; index to word mapping\")\n","s1 = (inp_convert(inp_lang, input_tensor_train[1]))\n","print(s1)\n","print (\"Target Language; index to word mapping\")\n","s2 = (tar_convert(targ_lang, target_tensor_train[1]))\n","print(s2)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Input Language; index to word mapping\n","['today', ',', 'more', 'than', 'ever', ',', 'the', 'great', 'majority', 'of', 'the', 'basque', 'people', 'remain', 'committed', 'to', 'non', 'violence', '.']\n","Target Language; index to word mapping\n","['die', 'gro', 'e', 'mehrheit', 'des', 'baskischen', 'volkes', 'tritt', 'heute', 'mehr', 'denn', 'je', 'fur', 'gewaltlosigkeit', 'ein', '.', '<end>']\n"],"name":"stdout"}]},{"metadata":{"id":"JvonfPCBJj8r","colab_type":"code","colab":{}},"cell_type":"code","source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 128\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 128\n","units = 512\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J2ztPjI_J56k","colab_type":"code","outputId":"f776f1b2-2276-4a2c-fdd7-b613a8bd24b8","executionInfo":{"status":"ok","timestamp":1553944760857,"user_tz":-330,"elapsed":308365,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape\n","print(vocab_inp_size)\n","print(vocab_tar_size)\n","print(example_input_batch.shape)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["30002\n","30002\n","(128, 20)\n"],"name":"stdout"}]},{"metadata":{"id":"_OZDK-q2J8pG","colab_type":"code","colab":{}},"cell_type":"code","source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.enc_units, \n","                                   return_sequences=True, \n","                                   return_state=True, \n","                                   recurrent_initializer='glorot_uniform')\n","\n","  def call(self, x, hidden):\n","    #print(x.shape)\n","    x = self.embedding(x)\n","    #print(x.shape)\n","    output, state = self.gru(x, initial_state = hidden)        \n","    return output, state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1iQ_g9tJOQlp","colab_type":"code","outputId":"ffa502e4-a742-4817-faee-478f98785fbb","executionInfo":{"status":"ok","timestamp":1553944763330,"user_tz":-330,"elapsed":309674,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n","print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Encoder output shape: (batch size, sequence length, units) (128, 20, 512)\n","Encoder Hidden state shape: (batch size, units) (128, 512)\n"],"name":"stdout"}]},{"metadata":{"id":"mjGUt-a4OT-i","colab_type":"code","colab":{}},"cell_type":"code","source":["class MultiplicativeAttention(tf.keras.Model):\n","  def __init__(self, units):\n","    super(MultiplicativeAttention, self).__init__()\n","    self.W1 = tf.keras.layers.Dense(units)\n","    self.W2 = tf.keras.layers.Dense(units)\n","    self.V = tf.keras.layers.Dense(1)\n","  \n","  def call(self, query, values):\n","    # hidden shape == (batch_size, hidden size)\n","    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n","    # we are doing this to perform addition to calculate the score\n","    hidden_with_time_axis = tf.expand_dims(query, 1)\n","    #print('shape of query is {}'.format(query.shape))\n","    #print('shape of hidden_with_time_axis is {}'.format(hidden_with_time_axis.shape))\n","    #print('shape of values {}'.format(values.shape))\n","    #print('shape of self.W1(values) is {}'.format(self.W1(values).shape))\n","    #print('shape of self.W2(hidden_with_time_axis) is {}'.format(self.W2(hidden_with_time_axis).shape))\n","    #print(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)).shape)\n","    \n","    # score shape == (batch_size, max_length, hidden_size)\n","    score = self.V((self.W1(values) * self.W2(hidden_with_time_axis)))\n","    \n","    #print('shape of score is {}'.format(score.shape))\n","\n","    # attention_weights shape == (batch_size, max_length, 1)\n","    # we get 1 at the last axis because we are applying score to self.V\n","    attention_weights = tf.nn.softmax(score, axis=1)\n","    #print('shape of attention_weights {}'.format(attention_weights.shape))\n","    \n","\n","    # context_vector shape after sum == (batch_size, hidden_size)\n","    context_vector = attention_weights * values\n","    context_vector = tf.reduce_sum(context_vector, axis=1)\n","    #print(context_vector.shape)\n","    \n","    return context_vector, attention_weights"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HeVRfOg7OlUl","colab_type":"code","outputId":"96a2a318-d83a-4f03-dc60-4eb29e77a797","executionInfo":{"status":"ok","timestamp":1553944763859,"user_tz":-330,"elapsed":308228,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["attention_layer = MultiplicativeAttention(10)\n","attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n","\n","print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n","print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Attention result shape: (batch size, units) (128, 512)\n","Attention weights shape: (batch_size, sequence_length, 1) (128, 20, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"V8WxPF6jOpUo","colab_type":"code","colab":{}},"cell_type":"code","source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.dec_units, \n","                                   return_sequences=True, \n","                                   return_state=True, \n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","    # used for attention\n","    self.attention = MultiplicativeAttention(self.dec_units)\n","\n","  def call(self, x, hidden, enc_output):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","    context_vector, attention_weights = self.attention(hidden, enc_output)\n","    #print(context_vector.shape)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n","    #print(x.shape)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x)\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state, attention_weights"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u0c1vMqlOxsC","colab_type":"code","outputId":"d4cf9827-1c83-47e4-ea6d-93eea6121d08","executionInfo":{"status":"ok","timestamp":1553944763862,"user_tz":-330,"elapsed":305415,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), \n","                                      sample_hidden, sample_output)\n","\n","print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Decoder output shape: (batch_size, vocab size) (128, 30002)\n"],"name":"stdout"}]},{"metadata":{"id":"d4ELsZkqSpbl","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam()\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  \n","  return tf.reduce_mean(loss_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tzSb24up0aZs","colab_type":"code","colab":{}},"cell_type":"code","source":["checkpoint_dir = '/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/multiplicative_attention/training_checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bU3Ys2pSBhnG","colab_type":"code","outputId":"1b2e9faf-d577-46d6-f8a4-ebeaeb1d6e59","executionInfo":{"status":"ok","timestamp":1553944775291,"user_tz":-330,"elapsed":312724,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f44f17feb00>"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"aKnrVbnX0c6A","colab_type":"code","colab":{}},"cell_type":"code","source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","        \n","  with tf.GradientTape() as tape:\n","    enc_output, enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)       \n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","      # passing enc_output to the decoder\n","      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # using teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","  \n","  return batch_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NcF1uNst0gVo","colab_type":"code","colab":{}},"cell_type":"code","source":["EPOCHS = 6\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","        print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                     batch,\n","                                                     batch_loss.numpy()))\n","  # saving (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","    #pickle.dump(optimizer, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_optimizer', 'wb'))\n","    #pickle.dump(encoder, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_encoder', 'wb'))\n","    #pickle.dump(decoder, open('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/pickle_decoder', 'wb'))\n","    \n","\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1vp4t2Nt0liP","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluate(sentence):\n","    attention_plot = np.zeros((max_length_targ, max_length_inp))\n","    \n","    sentence = preprocess_sentence(sentence)\n","\n","    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], \n","                                                           maxlen=max_length_inp, \n","                                                           padding='post')\n","    inputs = tf.convert_to_tensor(inputs)\n","    \n","    result = ''\n","\n","    hidden = [tf.zeros((1, units))]\n","    enc_out, enc_hidden = encoder(inputs, hidden)\n","\n","    dec_hidden = enc_hidden\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","    \n","    for t in range(max_length_targ):\n","        predictions, dec_hidden, attention_weights = decoder(dec_input, \n","                                                             dec_hidden, \n","                                                             enc_out)\n","        \n","        # storing the attention weights to plot later on\n","        attention_weights = tf.reshape(attention_weights, (-1, ))\n","        attention_plot[t] = attention_weights.numpy()\n","\n","        predicted_id = tf.argmax(predictions[0]).numpy()\n","\n","        result += targ_lang.index_word[predicted_id] + ' '\n","\n","        if targ_lang.index_word[predicted_id] == '<end>':\n","            return result, sentence, attention_plot\n","        \n","        # the predicted ID is fed back into the model\n","        dec_input = tf.expand_dims([predicted_id], 0)\n","\n","    return result, sentence, attention_plot"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dhQAhDWb5WLu","colab_type":"code","colab":{}},"cell_type":"code","source":["# function for plotting the attention weights\n","def plot_attention(attention, sentence, predicted_sentence):\n","    #print(attention)\n","    print(sentence)\n","    fig = plt.figure(figsize=(4,4))\n","    ax = fig.add_subplot(1, 1, 1)\n","    ax.matshow(attention, cmap='viridis')\n","    \n","    fontdict = {'fontsize': 10}\n","    \n","    ax.set_xticklabels(sentence, fontdict=fontdict, rotation=90)\n","    ax.set_yticklabels(predicted_sentence, fontdict=fontdict)\n","    #plt.savefig('/content/gdrive/My' + ' ' + 'Drive/Assignments_Sem2/NLU/assignment_2/multiplicative_attention/fig3_mul_attention')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IP8ho2tL5W-U","colab_type":"code","colab":{}},"cell_type":"code","source":["def translate(sentence):\n","    result, sentence, attention_plot = evaluate(sentence)\n","        \n","    print('Input: %s' % (sentence).encode('utf-8'))\n","    print('Predicted translation: {}'.format(result))\n","    \n","    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n","    return result"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LEoeGP8iGikf","colab_type":"code","colab":{}},"cell_type":"code","source":["def translate_tmp(sentence):\n","    result, sentence, attention_plot = evaluate(sentence)\n","        \n","    #print('Input: %s' % (sentence).encode('utf-8'))\n","    #print('Predicted translation: {}'.format(result))\n","    \n","    #attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n","    #plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n","    return result"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ryneNZKZ5Z9X","colab_type":"code","outputId":"8a1a0d5d-f0d5-41b4-cc7d-9cc82ed6f04c","executionInfo":{"status":"ok","timestamp":1553949060282,"user_tz":-330,"elapsed":2778,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# restoring the latest checkpoint in checkpoint_dir\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f44e2e4c358>"]},"metadata":{"tags":[]},"execution_count":54}]},{"metadata":{"id":"3myg2NTDpeH2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":369},"outputId":"06cbacee-19c7-41b8-93cd-6a425fad83b3","executionInfo":{"status":"ok","timestamp":1553971946903,"user_tz":-330,"elapsed":2043,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}}},"cell_type":"code","source":["#s = translate(' '.join(inp_convert(inp_lang, input_tensor_val[150]))).split(' ')\n","s = translate('the problems with fishmeal lie elsewhere .')\n","print(s)"],"execution_count":148,"outputs":[{"output_type":"stream","text":["Input: b'<start> the problems with fishmeal lie elsewhere . <end>'\n","Predicted translation: die probleme bei der unk liegt woanders . <end> \n","['<start>', 'the', 'problems', 'with', 'fishmeal', 'lie', 'elsewhere', '.', '<end>']\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQIAAAEcCAYAAAAsk7q7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XtYVNXeB/DvDAyWkAKK5OUY4CUv\nqJggxy5aaiKJl9D34B3MLPMVNPOkmHfzgscwTStTk0KeYyGTUQkq5vFSialgGt5QvAACCpogJsPM\nev/wZY4E6hqGcQ/w/TxPz8MMPxY/kL6z9p691lYJIQSIqE5TK90AESmPQUBEDAIiYhAQERgERAQG\nARGBQUBEYBAQERgEVAPl5OTg8OHDAICSkhKFu6kdbJVugMgUUVFRSExMRHFxMeLj4/Gvf/0LLi4u\neOONN5RurUbjjIBqlKSkJGzZsgUNGzYEAMyaNQu7d+9WuKuaj0FANYperwcAqFQqAMCdO3dQWlqq\nZEu1Ag8NqEYJCAjA2LFjcfHiRcybNw/JyckIDg5Wuq0aT8XVh9WvqKgIV69ehbu7Ow4dOoS0tDQM\nGjQIzs7OSrdW4+Xl5aGkpAS//fYb7Ozs0LFjRzRt2lTptmo8HhpYwNSpU5GXl4ezZ88iIiICzs7O\nCA8PV7qtWmHatGlo0aIFXnnlFfTt25chUE14aGABJSUl8PX1xerVqxESEoKBAwdCq9Uq3Vat4OLi\nguHDh6NTp07QaDTG5999910Fu6r5GAQWUFJSgvj4ePzwww+Ii4tDZmYmCgsLlW6rVujZs6fSLdRK\nPEdgASdPnkRcXBz69OmDHj16ICYmBi1btsQLL7ygdGtGYWFhxjPvlVm1atUj7MY0KSkpyM7OxoAB\nA5CXl4cmTZoo3VKNxyCwACEETp8+jaKiItz76/Xx8VGwq/IOHTp0389du3YNr7zyyiPsRl5ERASu\nXLmCS5cuQavV4qOPPsIff/yB2bNnK91ajcZDAwsIDg6GwWAo9y6BSqWyqiDo3r07AKC0tBQHDhzA\njRs3AAA6nQ7r1q2z2iA4ceIEoqOjMWbMGABAaGgoRo4cqXBXNR+DwAL0ej1iYmKUbkPK1KlTYW9v\nj0OHDqF3795ITk7G5MmTlW7rvkpLS6HT6YyHNQUFBbhz547CXdV8PDSwgK1bt+LmzZto3749bG3/\nm7XWNCMoM2bMGOMrbHR0NG7evIl58+Zh5cqVSrdWqV27duGTTz5BdnY2PD09cf78eYSHh+Pll19W\nurUajTMCC9i2bRv0ej1SU1ONz1nboUEZnU6HrKws2NjYICMjA02bNkVGRobSbd3Xyy+/jOeeew7p\n6emws7ODm5sbHnvsMaXbqvEYBBZgMBjw73//W+k2pEyZMgXHjx/HpEmTMGHCBBQVFWHUqFFKt3Vf\nBw4cwJYtW1BYWFjuROyXX36pYFc1Hw8NLGDNmjVwdXVFp06dyh0atG7dWsGuHqy0tLRcr9bK398f\n7733HlxdXcs936ZNG4U6qh2s/1++BkpOTgYAxMfHG59TqVRW+aqVnJyMxYsXo6SkBImJiVi5ciW8\nvb2t6pqHez311FN4/vnnlW6j1uGMwIJ0Ol25y2Ct0ahRo7BmzRqEhYUhOjoa+fn5mDRpEr766iul\nWyun7F2YM2fO4MaNG+jWrRtsbGyMn7fWw5m4uDh8/vnn+PLLL9GoUSOl27kvLjqygOTkZAwaNAgD\nBw4EAKxcuRIHDhxQuKvK2drawsnJyfh2XKNGjR54xaFSrl+/juvXr8PFxQVt2rTBzZs3jc9dv35d\n6fYqZTAYEBMTg5CQEKucDd6LhwYWsHr1anzxxRcICwsDAIwdOxaTJk2yyiltixYtsGrVKly/fh3b\nt29HUlKSVZ7LKLu2ITw8HH//+9/h6+uLJ598UuGuHiwxMREvvPAChg0bhn/84x944403YG9vr3Rb\nleKMwAJqyqssACxatAhubm7o1q0bUlNT0adPHyxcuFDptu4rKCgI+fn5eP/99zF8+HDMmTMH33//\nvdJtVWrz5s0ICQmBSqXC8OHDre5w614MAgv466vstGnTrPJVFgCKi4vh4OAALy8vdOjQATqdrtxJ\nTmvj5eWF1157DdOnT0dQUBCys7MRGRmpdFsV7N+/Hx07doSTkxMAYPDgwdixY4fVbqvGk4UWYDAY\n8N133yElJQUajQZdunSBv79/uZNb1uLVV19F27ZtK+yeNGPGDIU6erCJEycCADw8PODl5YUuXbpU\neCuRTMdzBNVo7969xo8dHR3x0ksvGR8fOHAAvXr1UqKtB3J0dERERITSbUjz8vJCWloaMjIyoFar\noVarodForGobuN69e9/3UFClUiEpKekRd/RwnBFUo4dtR7Z06dJH1Im87777DqmpqRXWRQwZMkTB\nruTs3bsXUVFRSE5ORlpamtLtGBUXF0MIgXXr1qFdu3bw9fWFwWDAwYMHcfHiRatc1MUgsJAzZ84Y\nX7U8PDzQqlUrpVuq1KBBg9C2bVu4uLgYn1OpVFa79df69etx7Ngx5OTkwM3NDT4+PvDx8YGHh4fS\nrVUwevRobN68udxz48aNw6ZNmxTq6P54aGAB8+bNQ1paGjp16mR8ZXjmmWcwa9asKo9ZXFyMX375\npcKWZ+a+cjs7O2PFihVmjfEoOTo64t1330XLli2VbuWh7OzssGzZMnTt2hVqtRrHjx833pfB2jAI\nLCAtLQ2xsbHGxwaDAcOHDzdrzPHjx6NZs2bltuWqjrckO3bsiJUrV6Jz587lDg2s8XwGAHTu3Bnz\n58/HrVu38NVXXyEqKgo+Pj7o2LGj0q1VsHr1asTHxxt3g3J3d8fatWsV7qpyDAILcHd3R25urvFs\ndkFBgdmLYmxsbPDBBx9UR3vlFBQUAECFE1jWGgTvv/8+5s+fj/nz5wMAnn/+ecyZM8cqV3uq1Wq4\nurqifv36xud2795tledfGATVaOjQoVCpVNDpdOjTpw+eeuopAMClS5fQvn37Ko15+/ZtAHd37927\nd2+Fa+wff/xxs3peunQpioqKKizrtVa2trblzre0bt0aarV1Xg4zbtw4tGjRotpncZbAIKhGq1ev\nrvYxBwwYAJVKVen/pCqVyuwbgM6dOxf79u1D48aNAdzdeFWlUmHr1q1mjWspTzzxBLZu3Yrbt2/j\n2LFj2LVrl9Uu5tFoNBaZxVlCnX7XoLS0FImJicjNzcX48eNx5swZuLu7m71iMCsrCx999BFOnjwJ\ntVoNT09PhIaGmrXt9pUrVyrc1Sc9Pd3sKxYDAwMRFxdnta9Uf3Xr1i188cUXSElJgZ2dHbp06YJR\no0ZZ5TX8GzduROvWrat9FmcJdToIwsPD4ezsjEOHDiE2NhabN2/G0aNHzb5kNSQkBCNGjICvry90\nOh0OHTqEbdu2Yf369SaPVVBQgIKCAoSHh2PZsmXGmUFpaSmmTJmCHTt2mNXrggULEBoaalUX5DxI\nUVER8vLy4OHhgeTkZJw8edJq7yvZr1+/CpcUV8cszhLq9KHBlStXsHTpUuPW2KNHj0ZiYqLZ4+r1\nevj5+RkfDxgwAF9//XWVxjp//jzi4uJw4cIF4wky4O6JqLJlzlVRdj7DYDCgT58+cHNzg42NjdUf\nGkydOhUTJkyAXq/H8uXLERwcjPDwcKxbt07p1irYuXOn0i1Iq9NBoNPpcPPmTeO0+Ny5cygpKTF7\nXDs7OyQkJMDX1xdCCBw8eBB2dnZVGsvb2xve3t4YOHAgnn32WbN7K2OJ8xmPQk26r+SZM2ewbNmy\nGvFWJ0Qd9uuvv4ohQ4YILy8v4efnJ/r37y8OHz5s9rg5OTkiPDxcDBw4UAwePFjMnj1b5ObmVmms\nuXPnCiGE6N27txg2bJgYOnRouf/MlZaWJvbv3y+EEGLt2rXirbfeqpbfgU6nE999953YsGGDEEKI\n06dPi5KSErPHDQoKEt9++63o16+fKCwsFJcvXxaBgYFmj2sJo0ePFunp6WL06NFCCCHOnj0rhg8f\nrnBXlavTQVDm2rVr4ubNm9U23qefflptY129elUIIcRrr70mvL29xdixY8XatWvF4cOHRVZWltnj\nBwUFicuXL4sDBw6IyZMni5ycHBEcHGz2uDNnzhTLly8Xw4YNE0IIER0dLd5++22zx01LSxOLFi0S\nP//8sxBCiM2bN4t9+/aZPa4lhISECCGEMQiEEGLkyJFKtfNAdfrQQKvVIjo6usJ76OaezMnPz8dP\nP/1U4dbdVTlbXPa23saNG433VExJScHHH3+MrKwss89p2NnZoUWLFtiwYQNGjBgBV1dXGAwGs8YE\nqv/8S3p6OoC7b8mVXaWZnp4OX19fs3u1lJr0VmedDoKNGzcatx6vTnv37kVSUpJxL72y3YrMCZjf\nf/8dqampOHbsGG7evIlmzZqhf//+Zveq0Wgwe/ZspKamYs6cOdi3b1+1bJ5R3edfFixYYPy47KIt\nW1tb4/jWtifg+fPnMXnyZCQlJcHJyQnr1q2Dl5cXlixZonRrlVN6SqKk0NBQi4wbFxcnXnjhBREQ\nECAGDBggXnzxRfHtt9+aNWbXrl3F2LFjxa5du8StW7eqqVMhCgsLxc6dO0VeXp4QQoiff/5ZZGZm\nmj2upc6//PLLLyIgIED069dPCCFEZGSkVR4aZGVliddee834OCcnp9xja1MnryOIiIiASqVCbm4u\nsrKy0KVLl3IXfJi7BHfw4MGIiooyblNVUFCAcePG4dtvv63ymHq9HmlpaTh69Ch+++03FBYWonnz\n5pg3b16VxktKSkLfvn3ve7PW6toePD8/HxqNBg0aNKiW8WrK9uvA3V2eRo0ahc6dO2Pp0qV47rnn\n0LNnT6XbqlSdPDRo27YtAMDBwcG4s3DZZbzLli0zOwhcXV3h6OhofOzk5GT2slm1Wg07Ozs89thj\nsLOzg06nq7Ak2RRLlixB3759ceLECTRv3tys3u41b948LFiwwHidwr1UKlW5VZlVUZM2hn399dfx\n4YcfYvHixTh27NhDN65RUp0MAnt7e3z//fc4fPgwfHx8jBfRlJaWllspVlUODg4YPHgwunfvDoPB\ngNTUVDRv3hzLly8HULUZxyuvvAJPT090794db775Jtzc3MzqsVGjRnj11Vdx6dKlCmOpVKoq76JT\ndqFPZeFSHf/DVrb9uqVud1YWalXVpk0bGAwGzJ0712pvwFKmTh4aAEBmZiYWLVqE8ePHG58r203I\n3MtVv/nmmwd+/tVXXzVr/OpQWlqKvLw8LFu2rNKNSqs6S7D0z/4oN4a9du2a8V2bqjpz5gx2796N\nN99802pXSQJ1OAiI6L+sN6KI6JFhEBARg4CIGAREhDrw9uGL/ZZJ1276bDzGvbFRqvZq13pSddve\nHoMhK6Olahuel9/qevMHIRj9TpTcuEeuSI/7ScJ0vOUvt735HTf5M+obN76O8eM3SNXWu5gvVWdK\nrwBQ0txJqm5D1AS8HiK3iYzmapH09/80fgomDlolVSsuZ0uPu+7QYrzZ/T2p2h1FX1T6PGcE93B3\nc3l4kYnaPGne20/349HSMuO6Pd304UVV4O5e/b9bt7aWuS26u0fVt5R7ELc2lunXrUMLs8dgEBAR\ng4CIGAREBAYBEYFBQERgEBARLBQEmZmZCAwMrPD8zJkzsWfPHkt8SyIyA2cERPTwKwu1Wi3279+P\noqIi5OTkICQkBOvWrUPPnj2Nm1vMmjULOp0OKpUKixcvNm7yMX36dFy4cAEdOnTAwoULjWPq9XrM\nmTMHly9fRmlpKcLCwtCjRw+MGTMGvr6++Omnn6BWqzFkyBB88803sLGxQVRUFG7fvo1Zs2bhjz/+\ngF6vx+zZs9GuXTuL/oKI6oSHbWoYFxcnAgIChE6nE/n5+eL5558XvXr1Env37hVC3N2//ocffhBC\nCJGQkCDeffddcfnyZdGhQweRnZ0tDAaDCAwMFKdOnRIzZswQP/74o/jmm29EZGSkEEKI/Px8ERAQ\nIIS4u//7li1bhBB399tfv369EEKIESNGiLS0NLFmzRrx9ddfCyHu3iyibN/4BzmfkSe7fyNRrdbP\nfux9Pye11sDHxwe2trZwdnZGw4YNcfnyZXTu3BkAcOLECbzzzjsAAF9fX6xduxYA0LJlS+Pdezt1\n6oSMjAzjeCkpKThy5AiOHj0KALhz545xq+uycZs0aYIOHToAuLu3f2FhIVJSUlBQUID4+HgAwO3b\ntx/au+zaAQD4z86Z0msTZNca/B7xNjrOWClVa8pag59jp+PZ/5G7zt6UtQYJ5z+Av8c7UrWmrDX4\n8cdw9O69VKpWdq1BwrkV8G81XboH2bUGu/e9hz49F0vVmrLWIPHkUvRvL7dvoSlrDXYUfQE/h2Dp\n+spIBcG9N7wQ/7+/X9mNO8o2/QTu7mVfth1TZRtXltFoNJg4cSICAgIqfK97t5y692MhBDQaDebM\nmYOuXbvKtE1EkqROFqampkKv16OgoAC3bt0qt0Nvp06dkJycDAD49ddf4enpCQC4dOkS8vLyYDAY\ncPz4cbRq1cr4NV26dDHe7CM/P1/6NuRdunRBUlISgLt3udm0aZPU1xHRg0kFQfPmzTFlyhQEBwdj\n6tSp5TZhDAsLw7Zt2zB27FhotVqEhYUBANq1a4eVK1ciKCgIXbt2RevWrY1f4+/vj/r162P48OGY\nOHEiunXrJtXs6NGjcenSJYwcORKzZ8+Gt7e3KT8rEd2H1KFBy5Yty+10O2TIEOPHrq6u2LCh4jrz\nrVu3Vnhu2bL/Hn8vXlzxGCw6+r/r9u+9bfe9H3/00UcyLRORCXgdARE9fEZQ2RWCRFS7cEZARAwC\nImIQEBHqwC7Gf7Sys0h9s/3yV5TJ1mb1cpAeEwButJa7359NiWmbZhZ1sswmm7on5P7cbBvL30Jd\nb0KtJvdm9deaesdAvdzVoyo7jUnDmlr/V5wREBGDgIgYBEQEBgERgUFARGAQEBEYBEQEBgERgUFA\nRGAQEBEYBEQEBgERgUFARGAQEBEYBEQEBgERgUFARGAQEBEYBEQEBgERgUFARKgDuxi7HJXfbdiU\nelXaeekx1cfPSdW1/KOZ9JhYCrSMvypVemGYi/y4AK56yf1Z6D1N+93mjP5Tqs55m730mH+0lq91\nPii/i7GqVG63YUPeNekxAUBcyZMrlNzt2Djun3dMqv8rzgiIiEFARAwCIgKDgIjAICAiMAiICFYY\nBFqtFhEREQ+tO3nyJFavXv0IOiKq/WrsdQTt27dH+/btlW6DqFawyiDIzMzEhAkTkJOTg+DgYLi5\nuSEyMhK2trZo2rQpFi1ahJSUFMTExHBWQFQNrDIILly4AK1Wi6KiIgwePBjOzs6IioqCo6Mjli9f\njsTERLi6uirdJlGtoRJCCKWbuJdWq8WxY8ewYMECAIC/vz9ycnLg6ekJACguLkb//v3RuXNnqRnB\nhXN5cGvVxOJ9E1k7v/pjsKM4utLPWeWMQKVSlXvs4uKC6OjyP0BycrLUWG+M/FT6++5Mnot+vgul\namXXGuwojILfEyFyY7aUX2uQ+PsS9O84S6rWlLUGpxa8jXbzVkrVmrLW4Oz/zEGb2EVStc7b6kvV\nJce8A99RH0j34HzwilRdwrkV8G81XarWlLUGpvwtmLLWYEdxNPzqj5Gur4zVvWsAAKmpqdDr9Sgo\nKMCff/4JlUqF9PR0AEB0dDROnTqlcIdEtYtVzgg8PDwwZcoUXLx4EVOnTkXz5s0RHh4OjUaDJk2a\nICgoCCkpKUq3SVRrWF0QBAYGIjAwsMLzsbGx5R77+vrC19f3UbVFVKtZ5aEBET1aDAIiYhAQEYOA\niMAgICJY4bsG1U19Kdci9cKUzSVla2U3tjSx/ql4E/6ZFwBPxV+XKo19c5P8uJiDI899JlUZ8GWo\n9Kj1bsr/O5Q0d6r2WjuDQXpMAFA3dpaqE0W3TBpXZS93Edb9cEZARAwCImIQEBEYBEQEBgERgUFA\nRGAQEBEYBEQEBgERgUFARGAQEBEYBEQEBgERgUFARGAQEBEYBEQEBgERgUFARGAQEBEYBEQEBgER\noQ7sYgzHBhapF/kF0kOK0lKpOhXqSY9pClXxHYvU+3w2TXrM0/Pl6zUT5HZRBoCCCfK3Zn8iRv5v\nobip3L+FXYYJu1kDQKlcvUqjMWlYU+v/ijMCImIQEBGDgIjAICAiMAiICAwCIgKDgIhgxUFw69Yt\n9O7dW+k2iOoEqw0CInp0rOrKwqKiIoSGhuLOnTvo1q0bAODw4cOIjIyEra0tmjZtikWLFiElJQWf\nf/45iouLMWPGDHh6eircOVHNphJCCKWbKBMTE4OLFy9i1qxZ2L59O1asWIEGDRogKioKjo6OWL58\nOdq1awdXV1fMnDkTO3bsgJ2d3QPHvHA2B25tnnxEPwGR9fJvNhkJ2Wsq/ZxVzQjOnTsHHx8fAED3\n7t1x7do1XL9+HaGhoQCA4uJiODk5wdXVFU8//fRDQwAAJg5aJf39E08uRf/24VK1hnMXpOp2lvwb\n/exGSNWqHeyl6gAgsWAD+ju/Llfs0kh+3NMR6P/0DKnajBHyAXt6/tt4ev5KqVrNM3JrDU4MWgjP\n+LnSPciuNfjlq+noEbRCqtbx58vS3z/h8ir4/22KXLFefg1DQvYa+DebLF1fGasKAiEE1Oq7py0M\nBgM0Gg0aN26M6OjocnXJyclSIUBEcqzqZKG7uztOnDgB4O7/7A0bNgQApKenAwCio6Nx6tQpxfoj\nqq2sKgiGDBmC1NRUBAcHIyMjAwCwePFihIeHY+TIkThy5Ag8PDwU7pKo9rGqQ4MGDRqUOwwICwsD\nAMTGxpar8/X1ha+v7yPtjag2s6oZAREpg0FARAwCImIQEBEYBEQEK3vXwBLEY6bt7mpqfXUSJTqL\n1Jc2a2jSuDrJ+gYZpl2dLluv8zZIj2mrNqH2tny/srWG6zekxzSlXvW3ZiaNKxo+YVL9X3FGQEQM\nAiJiEBARGAREBAYBEYFBQERgEBARGAREBAYBEYFBQERgEBARGAREBAYBEYFBQERgEBARGAREBAYB\nEYFBQERgEBARGAREBAYBEaEO7GKMsxctUq9u5Cw9pGytqv7j0mMCgNrVRapOc+y8SePK1jc+/ZhJ\n4zbeJTeu/kRjuQEDgCbz5P+E1ZGZ0rX270jWnm8hPSYAqNzk6q/6NjJp3KvPyv0t3A9nBETEICAi\nBgERgUFARGAQEBEYBESEGhYEWq0WERERSrdBVOvUqCAgIsuwiguKtFotzp49ixkzZuDWrVsYOHAg\nbGxsEBQUhD179qCkpASbNm0q9zUffPABHn/8cUyaNEmhrolqD6udEej1enh4eCAmJgYtWrTAwYMH\njZ9LSEjAlStXGAJE1UQlhBBKN1HZjAAAtm3bhgYNGiAiIgJt27aFEALbt29HRkYGtm/fjnr16j10\n7AtpmXDrYNploES1UbfxkTiycVqln7OKQwOVSmX8uLS01PixjY2N8eOyvMrKykKbNm2QmJiIwYMH\nP3TsN7u/J93HjqIv4OcQLFWresJBqi7xylr0b/q/cmOasNYg4dwK+LeaLlUrrt+QHjexYAP6O78u\nVat6TH6tQUL2Gvg3myxVq28qt9Zg55H56NdtvnQP6sjrUnWJvVah/94pcoP+r9zfAQAknliM/p5y\nf4+mrDU4snEauo2PlK6vjFUcGjg4OCAvLw8AcOTIkQfWvvjii1iyZAk+/vhjXLt27VG0R1TrWUUQ\n9OjRAxkZGRgzZgzOnz9fboZQGWdnZ4SFhWH+/PmPpkGiWs4qDg0cHByg1WqNj19/vfzUdMaMGRW+\nZsCAARgwYIDFeyOqC6xiRkBEymIQEBGDgIgYBEQEBgERgUFARLCStw8tSehKH15UhXq1Wj5DVZK1\nemf5q9RMqVcXFZs0LjR2ptVXM/W5yxapvRLrKVfYC7gS6yZVKvpKf3sAQHZfuasmi/5u2r/Z9Zdv\nm9bIX3BGQEQMAiJiEBARGAREBAYBEYFBQERgEBARGAREBAYBEYFBQERgEBARGAREBAYBEYFBQERg\nEBARGAREBAYBEYFBQERgEBARGAREhDqweSnUD76hapXrH5e/Jbhsra6hCWOaUG9XWGjSuEKy3vD/\nt6qXpZe8PbuNk6P0mKbcSr7ZD5Ibna6Rr73RvZn09wcA+yt6qbrUF6NMGPU9pEvXV35bds4IiIhB\nQEQMAiICg4CIwCAgIjAIiAgMAiKCwtcRaLVaHDlyBDY2Nli4cKFJX3vq1CnUq1cP7u7uFuqOqO5Q\nfEbQoEEDk0MAAHbt2oULFy5Uf0NEdZDiVxZmZWUhMDAQWq0Whw8fRmRkJGxtbdG0aVMsWrQIKpUK\n//znP5GdnY2uXbsiISEB69evx5YtW+Ds7IxGjRqhc+fOSv8YRDWaSggTrxOtRlqtFv/5z3+QmZkJ\nrVaLIUOGICoqCo6Ojli+fDnatWsHBwcHxMbG4pNPPsGePXvw1ltv4dSpU5g5cyb8/Pzw0ksvPfB7\nXPj9Mtw6/u0R/URE1suQ0wbqJ89W+jnFZwRlrl27hosXLyI0NBQAUFxcDCcnJ+Tm5uKZZ54BAPTq\n1Qu2tqa1/IZ3uHTtztub0e/x0VK1Ns2bStUlpP8L/q3/KVX7p1sjqToA2JM0Ey/1XSZVa/fz79Lj\n7iiOhl/9MVK1pryGmPS7lVxrkJC9Bv7NJkv3gHp2cuNmRMLffZpUrSlrDX75ajp6BK2Qqv1p1Trp\ncdVPnoUhp410fWWsJgg0Gg2aNGmC6Ojocs9/9tlnsLGxAQCoVCYuICIiKYqfLCzTsGFDAEB6ejoA\nIDo6GqdOnULLli1x4sQJAMCBAweg199dvaVSqYwfE5F5rGZGAACLFy9GeHi4cXYQFBQEd3d3xMXF\nYcSIEejevTscHe9OG729vfH+++/D3t4ePXr0ULhzoppN0SAIDAxEYGCg8bG3tzdiY2PL1dy4cQPD\nhg2Dn58fcnNzsWPHDgDA0KFDMXTo0EfaL1FtZVUzgsrY29sjISEBGzduhMFgQHi4/Mk/IpJj9UGg\n0Wjw4YcfKt0GUa1mNScLiUg5DAIiYhAQUQ04R2AuceeORepLz1+QHlO21taEMQHA9scjUnUGk0YF\nDH/+aeJXyJH+3ebkSo9pSq0/35VTAAAAl0lEQVQpSi/K7WLsIFkHAPgKcIhNlir1i/WSHnaXAfBr\nJle/6z5/DJwREBGDgIgYBEQEBgERgUFARGAQEBEYBEQEBgERgUFARGAQEBEYBEQEBgERgUFARGAQ\nEBEYBEQEBgERgUFARGAQEBEYBEQEBgERgUFARABUwpSb3BNRrcQZARExCIiIQUBEYBAQERgERAQG\nAREB+D+S5hmTWztHBgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 288x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["die probleme bei der unk liegt woanders . <end> \n"],"name":"stdout"}]},{"metadata":{"id":"sNFHQujn5dVh","colab_type":"code","colab":{}},"cell_type":"code","source":["ref = list()\n","for i in range(1000):\n","  ref_tmp = list()\n","  ref_tmp.append(tar_convert(targ_lang, target_tensor_val[i]))\n","  ref.append(ref_tmp)\n","  \n","cand = list()\n","for i in range(1000):\n","  s = translate_tmp(' '.join(inp_convert(inp_lang, input_tensor_val[i]))).split(' ')\n","  cand.append(s)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GpdXSa_e5gTk","colab_type":"code","outputId":"c1251915-2b84-4174-a13d-126c48a9e749","executionInfo":{"status":"ok","timestamp":1553946845524,"user_tz":-330,"elapsed":2367525,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":["print(ref[0:5])\n","print(cand[0:5])\n","print(len(ref))\n","print(len(cand))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["[[['seine', 'amtszeit', 'beendet', ',', 'ohne', 'da', 'es', 'ihm', 'gelungen', 'ware', ',', 'einen', 'krieg', 'auf', 'europaischem', 'boden', 'zu', 'verhindern', '.', '<end>']], [['sowie', 'die', 'verwaltung', 'des', 'internets', 'der', 'dinge', 'zum', 'zwecke', 'der', 'achtung', 'der', 'privatsphare', 'und', 'des', 'schutzes', 'personenbezogener', 'daten', '.', '<end>']], [['in', 'den', 'landern', 'westeuropas', 'und', 'in', 'den', 'vereinigten', 'staaten', 'hat', 'freiwilligentatigkeit', 'lange', 'traditionen', '.', '<end>']], [['ich', 'bedaure', ',', 'dass', 'kommissar', 'verheugen', 'dies', 'nicht', 'gewurdigt', 'hat', '.', '<end>']], [['hat', 'die', 'kommission', 'daran', 'gedacht', ',', 'die', 'charta', 'der', 'grundrechte', 'als', 'eines', 'der', 'unk', 'in', 'diese', 'initiative', 'aufzunehmen', '?', '<end>']]]\n","[['amtszeit', 'zu', 'andern', 'und', 'dass', 'es', 'nicht', 'gelungen', 'ist', ',', 'einen', 'krieg', 'auf', 'europaischem', 'boden', 'zu', 'verhindern', '.', '<end>', ''], ['der', 'unk', 'der', 'dinge', 'im', 'hinblick', 'auf', 'die', 'wahrung', 'der', 'privatsphare', 'und', 'der', 'personenbezogenen', 'daten', '.', '<end>', ''], ['freiwilligentatigkeit', 'hat', 'in', 'den', 'landern', 'westeuropas', 'und', 'in', 'den', 'usa', '.', '<end>', ''], ['ich', 'bedauere', ',', 'dass', 'kommissar', 'verheugen', 'nicht', 'daran', '.', '<end>', ''], ['beabsichtigt', ',', 'die', 'charta', 'der', 'grundrechte', 'der', 'grundrechte', 'in', 'die', 'initiative', 'dieser', 'initiative', 'aufzunehmen', '?', '<end>', '']]\n","5000\n","5000\n"],"name":"stdout"}]},{"metadata":{"id":"wanR8twMDV25","colab_type":"code","outputId":"8bb2a981-0232-46ab-8f1a-0fd244cbcc27","executionInfo":{"status":"ok","timestamp":1553946847668,"user_tz":-330,"elapsed":2368830,"user":{"displayName":"Rahul Bansal","photoUrl":"https://lh3.googleusercontent.com/-Z7YrcGJvCfc/AAAAAAAAAAI/AAAAAAAAADk/yKx4p_R3LSI/s64/photo.jpg","userId":"00373750895463665640"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# two references for one document\n","from nltk.translate.bleu_score import corpus_bleu\n","#references = [[['this', 'is', 'a', 'test'], ['this', 'is' 'test']]]\n","#candidates = [['this', 'is', 'a', 'test']]\n","score = corpus_bleu(ref, cand)\n","print(score)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["0.19972773123654472\n"],"name":"stdout"}]},{"metadata":{"id":"XbjAUtDSd719","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}